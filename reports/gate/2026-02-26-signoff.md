Gate Decision: PASS
Date: 2026-02-26
Reviewer: codex
Providers Enabled: claude, codex, gemini, opencode, qwen
Version Locks:
- claude: 2.1.59 (macos)
- codex: 0.105.0 (macos)
- gemini: 0.30.0 (macos)
- opencode: 1.2.14 (macos)
- qwen: 0.10.6 (macos)
Open Risks:
- MCP startup errors may appear in stderr for some providers while output remains valid; treat as warning and monitor.
Follow-up Actions:
- CI wiring completed on 2026-02-26: runtime gate is auto on push/PR; capability probes are manual on self-hosted macOS (`.github/workflows/gate.yml`).
- Step 0 interface/DoD freeze completed: `runtime/contracts.py`, `runtime/artifacts.py`, `docs/implementation/step0-interface-freeze.md`.
- Step 1 adapter baseline completed: real `claude/codex` adapters and dry-run evidence (`reports/adapter-contract/2026-02-26/step1-adapter-dryrun.md`).
- Step 2 unified entrypoint completed: `mco review` now drives config load + dispatch + strict normalize + artifact writing.
- Step 2 smoke evidence: `mco review` produced full artifact set with `findings_count=1`, and repeated same request returned `created_new_task=false` (idempotent replay).
- Step 3 baseline completed: gemini/opencode/qwen adapters are wired into registry, parse gate uses structured JSON contract validation, and event-stream nested JSON extraction is implemented.
- Step 3 real 5-provider parity evidence: `reports/review/task-b234caf82d5b25e0/run.json` shows `parse_success_count=5`, `parse_failure_count=0`, `terminal_state=COMPLETED`.
- Runtime gate report refreshed after parser hardening and parallel fan-out changes: `reports/adapter-contract/2026-02-26/runtime-gh-report.md` (`Ran 52 tests`).
- Capability probes refreshed after timeout wrapper hardening: `docs/probes/2026-02-26/summary.md` and `docs/probes/2026-02-26/lock-summary.yaml` both show 5-provider C0/C1/C2 enabled.
- Parallel execution benchmark completed with `wait-all` strategy: `reports/adapter-contract/2026-02-26/step4-parallel-benchmark.md` (serial 143.16s -> parallel 74.01s, 48.3% reduction).
- Step5 full-parallel benchmark script is now in place and validated: `scripts/run_step5_parallel_benchmark.sh`, with latest evidence in `reports/adapter-contract/2026-02-26/step5-parallel-benchmark.md` (serial 138s -> full-parallel 39s, 71.7% reduction, parse 5/5 on both runs).
- Step5 benchmark summary now includes metric separation to avoid ambiguity: `providers_total`, `parse_success_rate`, `effective_findings_count`, `zero_finding_provider_count`, and `metric_note`.
- Non-blocking scheduled benchmark CI is wired: `.github/workflows/benchmark.yml` (daily + manual dispatch, self-hosted macOS, artifact upload).
