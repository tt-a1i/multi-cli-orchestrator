# v0.1.0 - Minimum Usable Release

Date: 2026-02-26

## Scope

`v0.1.0` establishes a usable baseline for multi-provider orchestration:
- Unified entrypoints: `mco review` and `mco run`
- 5-provider adapter wiring: `claude`, `codex`, `gemini`, `opencode`, `qwen`
- Wait-all parallel fan-out with idempotency/retry semantics
- Review-mode structured parse contract gate with canonical findings output
- Gate and benchmark workflows in GitHub Actions

## Installation

## Prerequisites

- Python 3.11+
- `jq` and `ripgrep` (for scripts and probes)
- At least one configured provider CLI:
  - `claude`
  - `codex`
  - `gemini`
  - `opencode`
  - `qwen`

## Clone and run

```bash
git clone git@github.com:tt-a1i/mco.git
cd mco
./mco review --repo . --prompt "Review for bugs." --providers claude,codex --json
```

Generic run mode:

```bash
./mco run --repo . --prompt "Summarize this repository architecture." --providers claude,codex --json
```

## Configuration

Minimal `mco.example.json` style config:

```json
{
  "providers": ["claude", "codex", "gemini", "opencode", "qwen"],
  "artifact_base": "reports/review",
  "state_file": ".mco/state.json",
  "policy": {
    "timeout_seconds": 180,
    "max_retries": 1,
    "high_escalation_threshold": 1,
    "require_non_empty_findings": true,
    "max_provider_parallelism": 0,
    "allow_paths": [".", "runtime", "scripts"],
    "enforcement_mode": "strict",
    "provider_permissions": {
      "claude": {"permission_mode": "plan"},
      "codex": {"sandbox": "workspace-write"}
    },
    "provider_timeouts": {
      "claude": 300,
      "codex": 240
    }
  }
}
```

Run with config:

```bash
./mco review --config ./mco.example.json --repo . --prompt "Review for security and reliability risks."
```

## Artifact Outputs

Each task writes to `<artifact_base>/<task_id>/`:
- `summary.md`
- `decision.md`
- `findings.json`
- `run.json`
- `providers/*.json`
- `raw/*.log`

Gate and benchmark reports are written under:
- `reports/adapter-contract/<date>/`

## Common Errors

1. Provider unavailable (`detected=false` or `auth_ok=false`)
- Verify provider CLI is installed and authenticated.
- Run provider-specific auth checks first.

2. JSON parse success but low effective findings
- This is expected in some runs.
- Distinguish:
  - parse health: `parse_success_count`, `providers_total`, `parse_success_rate`
  - retained findings: `effective_findings_count`, `zero_finding_provider_count`

3. Timeout-related partial success
- Increase provider-specific timeout using `provider_timeouts` or `--provider-timeouts`.
- Default profile is tuned for `claude` and `codex`, but project context can still require higher values.

4. YAML config load error
- Install `pyyaml`, or use `.json` config files only.

## FAQ

Q: Why can `parse_success_count` be high while findings are lower?  
A: Parsing validates contract structure; findings can still be empty or dropped by schema filtering.

Q: What is the difference between `mco review` and `mco run`?  
A: `review` enforces findings contract/decisioning; `run` is generic execution aggregation for agent orchestration.

Q: Does `allow_paths` provide OS-level sandboxing by itself?  
A: No. `allow_paths` is enforced by orchestrator path validation/policy checks. Provider-level sandbox depends on each provider's supported permission keys.

Q: What does `max_provider_parallelism=0` mean?  
A: Full parallelism across selected providers.

Q: Does one provider failure stop the run?  
A: No. Execution is `wait-all`; terminal state may become `PARTIAL_SUCCESS`.

Q: Is this production-ready?  
A: `v0.1.0` is a minimum usable baseline with gate coverage; rollout should still include repo-level policy/security hardening.
